{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Some imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "#enable to download ffmpeg.win32.exe\n",
    "# import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the file iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simple iterator used to read file-by-file using cv2.imread\n",
    "class ReadFileIterator(object):\n",
    "    def __init__(self, filepath, fileEnding = '*.jpg'):\n",
    "        self.filenames = glob.glob(os.path.join(filepath, fileEnding))\n",
    "        self.index = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if(self.index < len(self.filenames)):\n",
    "            i = self.index\n",
    "            self.index+=1 \n",
    "            return cv2.imread(self.filenames[i])\n",
    "        else :\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The AdvancedLaneFinder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdvancedLaneFinder(object):\n",
    "    def __init__(self):\n",
    "        #Members used for undistortion\n",
    "        self.camMatrix = None   #CamMatrix\n",
    "        self.distCoeff = None   #Distortion coefficient\n",
    "        self.rotVec = None      #rotation vectors\n",
    "        self.traVec = None      #translation vectors\n",
    "        self.persTransM = None\n",
    "        self.persInvTransM = None\n",
    "        self.leftFit = None     #Polygon for left lane\n",
    "        self.rightFit = None    #polygon for right lane\n",
    "        self.leftCurverad = None\n",
    "        self.rightCurverad = None\n",
    "        self.carPx = None\n",
    "        self.carPos = None      #carPos in meters, negative means left to middle of lane\n",
    "        self.noRecoveries = 0   #no of recoveries (fetching histogram again)\n",
    "        \n",
    "        self.counter = 0        #counter variable\n",
    "    \n",
    "\n",
    "    #static: display an image\n",
    "    def showImage(img, title=\"image\"):\n",
    "        cv2.imshow(title,img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def writeImage(img, filename=\"R:\\output.jpg\"):\n",
    "        cv2.imwrite(filename, img)\n",
    "\n",
    "    def writeMembers(self, path):\n",
    "        dataToWrite = (self.camMatrix, self.distCoeff, self.rotVec, self.traVec)\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(dataToWrite, file)\n",
    "            print (\"Write persistency to \", path)\n",
    "    \n",
    "    def readMembers(self, path):\n",
    "        with open(path, 'rb') as file:\n",
    "            dataToRead = pickle.load(file)\n",
    "            self.camMatrix, self.distCoeff, self.rotVec, self.traVec = dataToRead\n",
    "            print (\"Read persistency to \", path)\n",
    "            \n",
    "        \n",
    "    #display an example normal/ undistorted\n",
    "    def exampleShowUndistorted(self, filepath):\n",
    "        img = cv2.imread(filepath)\n",
    "        undiImg = cv2.undistort(img, self.camMatrix, self.distCoeff, None, self.camMatrix)        \n",
    "        cv2.imshow(\"Distorted\", img)\n",
    "        AdvancedLaneFinder.writeImage(img, \"R:/Distorted.jpg\")\n",
    "        cv2.imshow(\"Undistorted\", undiImg)\n",
    "        AdvancedLaneFinder.writeImage(undiImg, \"R:/Undistorted.jpg\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def undistortImage(self, image):\n",
    "        return cv2.undistort(image, self.camMatrix, self.distCoeff, None, self.camMatrix)     \n",
    "        \n",
    "    def initializeTransformMatrix(self, image = None):\n",
    "        src = np.float32(\n",
    "            [[577,461],\n",
    "             [707,461],\n",
    "             [1029,666],\n",
    "             [275,666]])\n",
    "        dst = np.float32(\n",
    "            [[275, 30],\n",
    "             [1029,30],\n",
    "             [1029,720],\n",
    "             [275,720]])\n",
    "\n",
    "        #TAKE CARE:\n",
    "        #In order to calculate a valid curvature radius, the dimensions of \n",
    "        #x and y are very important. Changing in non-adequate way will result\n",
    "        #in a completly other curvature result\n",
    "\n",
    "        #matrix from normal into birds view\n",
    "        self.persTransM = cv2.getPerspectiveTransform(src, dst)\n",
    "        #and the other way round\n",
    "        self.persInvTransM = cv2.getPerspectiveTransform(dst, src)\n",
    "        \n",
    "        \n",
    "        #when passing an image, hightlight the source points\n",
    "        if not image is None:\n",
    "            cv2.circle(image, tuple(src[0]), 5, (255,255,255),4)\n",
    "            cv2.circle(image, tuple(src[1]), 5, (255,255,255),4)\n",
    "            cv2.circle(image, tuple(src[2]), 5, (255,255,0),4)\n",
    "            cv2.circle(image, tuple(src[3]), 5, (255,255,0),4)\n",
    "        \n",
    "        return image\n",
    "              \n",
    "    #parameter True means from normal in birds perspective\n",
    "    #False will do the transformation in the opposite direction  \n",
    "    def transformPerspective(self, image, forward = True):\n",
    "        dim = image.shape[:2]\n",
    "        if True == forward:\n",
    "            return cv2.warpPerspective(image, self.persTransM, (dim[1], dim[0]))\n",
    "        return cv2.warpPerspective(image, self.persInvTransM, (dim[1], dim[0]))\n",
    "        \n",
    "    #switch into the HLS color space\n",
    "    #filter all pixels below a certain threshold\n",
    "    def applyColorSpaceTransformation(self, image, thresh = 150):\n",
    "        sat = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "        red = image[:,:,2]\n",
    "        output = np.zeros_like(sat)\n",
    "        output[(sat>=thresh) & (red >= thresh)] = 255\n",
    "        return output\n",
    "        \n",
    "\n",
    "    def applyGradient(self, image, directionThresh, xgradThresh):\n",
    "        img = image\n",
    "        if(len(image.shape) ==3):\n",
    "            img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        #apply sobel operator in X direction\n",
    "        sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=9)\n",
    "        sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=9)\n",
    "        \n",
    "        #calc the absolute gradiant direction\n",
    "        directionThresh = (directionThresh[0] * np.pi / 180.,directionThresh[1] * np.pi / 180.) \n",
    "        absgraddir = np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "        \n",
    "        #take the absolute of the sobel\n",
    "        absSobel = np.absolute(sobelx)\n",
    "        #convert to 8 bit gray-value\n",
    "        scaledSobel = np.uint8(255*absSobel/np.max(absSobel))\n",
    "        output = np.zeros_like(scaledSobel)\n",
    "        output[ ((absgraddir >= directionThresh[0]) & (absgraddir <= directionThresh[1]) ) &\\\n",
    "            ((scaledSobel >= xgradThresh[0]) & (scaledSobel <= xgradThresh[1]) )] = 255\n",
    "        return output\n",
    "\n",
    "\n",
    "    def calibrateCameraUsingImage(self, imagepath):\n",
    "        #member to store image and object points of each camera\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        #we're expecting a grid of 9,6 corners\n",
    "        #TODO: it is not working for a shape of 9,5!!! What's the reason for that?\n",
    "        noCorners = (9,6)\n",
    "        \n",
    "        #object points - 3D points are simply numbered from 0 to x/y\n",
    "        #this var is used as dummy for the objectpoints\n",
    "        objp = np.zeros( ((noCorners[0]*noCorners[1]), 3), np.float32)\n",
    "        #align only the first two columns to the grid\n",
    "        objp[:,:2] = np.mgrid[0:noCorners[0], 0:noCorners[1]].T.reshape(-1,2)\n",
    "\n",
    "        #CamScope will store the hight and width of the camera scope    \n",
    "        camScope = None\n",
    "        #iteratore over all images in the path\n",
    "        for image in ReadFileIterator(imagepath):\n",
    "            #first step, we need to convert the image into grayscale image to allow\n",
    "            #easier detection of the chessfield\n",
    "            \n",
    "            img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #store the camScope and guarantee that we're not mixing up\n",
    "            #images from different cameras\n",
    "            if(camScope == None):\n",
    "                camScope = img.shape[::-1];\n",
    "            else:\n",
    "                #calibration image 15 is different scale\n",
    "                #therefore i've disabled the assertion\n",
    "                #assert(camScope == img.shape[::-1])\n",
    "                pass\n",
    "            #find the chessboard, store the image points in corners\n",
    "            ret, corners = cv2.findChessboardCorners(img, noCorners, None)\n",
    "            \n",
    "            if True == ret :\n",
    "                #success, store the image-/object points\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "                img = cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "                cv2.imshow(\"Chessboard\", img)\n",
    "                cv2.waitKey(500)\n",
    "                \n",
    "\n",
    "        #after iterating through all our camera_cal images, we do the calibration\n",
    "        print (\"Calibration using {0:d} Objectpoints\".format(len(objpoints)))\n",
    "        if(len(objpoints)==len(imgpoints) and 0!=len(objpoints) ):\n",
    "            ret, self.camMatrix, self.distCoeff, self.rotVec, self.traVec = \\\n",
    "                cv2.calibrateCamera(objpoints, imgpoints, camScope, None, None)\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        return self.camMatrix is not None \n",
    "    \n",
    "    #apply the color space gradient and the direction gradient\n",
    "    #function and return as a result the logical OR of the two \n",
    "    #resulting pictures\n",
    "    def findEdges(self, image):\n",
    "        val = self.applyColorSpaceTransformation(image, 120)\n",
    "        val2 = self.applyGradient(image, (40,74), (20, 100))\n",
    "        val3 = np.zeros_like(val2)\n",
    "        val3[(val == 255) | (val2 == 255) ] = 255\n",
    "        return val3\n",
    "    \n",
    "    \n",
    "    \n",
    "    #find polynominals\n",
    "    #start with initial matching searching for two max values in \n",
    "    #histogram of the lower half of the image\n",
    "    #\n",
    "    def findPolynomials(self, image):\n",
    "        \n",
    "        out_img = np.dstack((image*1, image*0, image*0))\n",
    "        #identify the elements in the image, which aren't zero - meaning not black\n",
    "        #this is done by image.nonzero!!\n",
    "        nonzero = image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Set the width of the windows +/- margin\n",
    "        diff_margin = 80\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        \n",
    "        \n",
    "        leftx = None\n",
    "        lefty = None \n",
    "        margin = diff_margin\n",
    "        if( (self.leftFit == None) | (self.rightFit == None)):\n",
    "            #create historgram along x-axis from the lower half of the picture\n",
    "            #to find an appropriate startpoint for lane detection\n",
    "            histogram = np.sum(image[np.int(image.shape[0]/2):,:], axis = 0)\n",
    "            midpoint = np.int(histogram.shape[0]/2)\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "            \n",
    "            noWindows = 9\n",
    "            window_height = np.int(image.shape[0]/noWindows)\n",
    "            \n",
    "            # Current positions to be updated for each window\n",
    "            # remember the previously used lefx and rightx to\n",
    "            # identify a tendency\n",
    "            # Assumption: the curvature will stay relatively constant\n",
    "            # in one direction.\n",
    "            leftx_current = leftx_base\n",
    "            rightx_current = rightx_base\n",
    "            leftx_prev = leftx_base\n",
    "            rightx_prev = rightx_base\n",
    "            tendencyLeft = 0\n",
    "            tendencyRight = 0\n",
    "\n",
    "            # Create empty lists to receive left and right lane pixel indices\n",
    "            left_lane_inds = []\n",
    "            right_lane_inds = []\n",
    "            \n",
    "            #initial margin is choosen very big so that even in case\n",
    "            #of that the max-value of the histogram isn't reflecting\n",
    "            #the start of the lane, we have the change to identify the \n",
    "            #lane in the first window.\n",
    "            #This workaround will provide better results in case that\n",
    "            #we start to initialize in a sharp turn\n",
    "            margin = int((rightx_base - leftx_base)/2)\n",
    "            # Step through the windows one by one\n",
    "            for window in range(int(noWindows/1)):\n",
    "                #in the first two iterations we won't really have a \n",
    "                #tendency. We'll start taking tendency into considerations\n",
    "                #at the second window (meaning 3rd iteration)\n",
    "                if window > 1:\n",
    "                    tendencyLeft = int((leftx_current - leftx_prev) )\n",
    "                    tendencyRight = int((rightx_current - rightx_prev) )\n",
    "                leftx_prev = leftx_current\n",
    "                rightx_prev = rightx_current\n",
    "                \n",
    "                # Identify window boundaries in x and y (and right and left)\n",
    "                win_y_low = image.shape[0] - (window+1)*window_height\n",
    "                win_y_high = image.shape[0] - window*window_height\n",
    "                #enlarge the window in direction of tendency to \n",
    "                #have the chance to identify really sharp curves\n",
    "                win_xleft_low = leftx_current - margin + tendencyLeft\n",
    "                win_xleft_high = leftx_current + margin + tendencyLeft\n",
    "                win_xright_low = rightx_current - margin + tendencyRight\n",
    "                win_xright_high = rightx_current + margin + tendencyRight\n",
    "                \n",
    "                # Draw the windows on the visualization image\n",
    "                cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "                cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "                # Identify the nonzero pixels in x and y within the window\n",
    "                #big matrix which contains true/false and this is converted into a matrix of indicies (nonzero)\n",
    "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "                # Append these indices to the lists\n",
    "                left_lane_inds.append(good_left_inds)\n",
    "                right_lane_inds.append(good_right_inds)\n",
    "                # If you found > minpix pixels, recenter next window on their mean position\n",
    "                if len(good_left_inds) > minpix:\n",
    "                    leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "                else:\n",
    "                    #if not - move the window in direction of tendency\n",
    "                    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,0,255), 2)\n",
    "                    leftx_current += int(tendencyLeft/1) \n",
    "                if len(good_right_inds) > minpix:        \n",
    "                    rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "                else:\n",
    "                    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,0,255), 2)\n",
    "                    rightx_current += int(tendencyRight/1)\n",
    "                \n",
    "                #adjust the margin - the first margin is bigger than the\n",
    "                #diff_margin in order to take care of misleading histogram means\n",
    "                margin = diff_margin\n",
    "                \n",
    "            # Concatenate the arrays of indices (from list to array)\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "            \n",
    "            # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds] \n",
    "        \n",
    "            # Fit a second order polynomial to each\n",
    "            self.leftFit = np.polyfit(lefty, leftx, 2)\n",
    "            self.rightFit = np.polyfit(righty, rightx, 2)\n",
    "        else:\n",
    "            left_lane_inds = ((nonzerox > (self.leftFit[0]*(nonzeroy**2) + self.leftFit[1]*nonzeroy + self.leftFit[2] - margin)) & (nonzerox < (self.leftFit[0]*(nonzeroy**2) + self.leftFit[1]*nonzeroy + self.leftFit[2] + margin))) \n",
    "            right_lane_inds = ((nonzerox > (self.rightFit[0]*(nonzeroy**2) + self.rightFit[1]*nonzeroy + self.rightFit[2] - margin)) & (nonzerox < (self.rightFit[0]*(nonzeroy**2) + self.rightFit[1]*nonzeroy + self.rightFit[2] + margin)))  \n",
    "            \n",
    "            # Again, extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds]\n",
    "            # Fit a second order polynomial to each\n",
    "            self.leftFit = np.polyfit(lefty, leftx, 2)\n",
    "            self.rightFit = np.polyfit(righty, rightx, 2)\n",
    "            \n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "        left_fitx = self.leftFit[0]*ploty**2 + self.leftFit[1]*ploty + self.leftFit[2]\n",
    "        right_fitx = self.rightFit[0]*ploty**2 + self.rightFit[1]*ploty + self.rightFit[2]\n",
    "        \n",
    "        ptsl = np.column_stack( (left_fitx.astype(np.int32), ploty.astype(np.int32)))\n",
    "        ptsr = np.column_stack( (right_fitx.astype(np.int32), ploty.astype(np.int32)))\n",
    "        pts = np.concatenate((ptsl, np.flipud(ptsr)))\n",
    "        cv2.polylines(out_img, [ptsl], False, (0,0,255), 8)\n",
    "        cv2.polylines(out_img, [ptsr], False, (0,0,255), 8)\n",
    "        cv2.fillPoly(out_img, [pts], (0,255,0))\n",
    "\n",
    "        y_eval = np.max(ploty)\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        # MAKE SURE YOU DIDN'T CHANGE THE DIMENSIONS IN X-AXIS DURING\n",
    "        # PERSPECTIVE TRANSFORMATION\n",
    "        ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        \n",
    "        #straight Sanity check: if the distance between the lanes \n",
    "        #at the car and in the horizont are differing in about 1m - it's time\n",
    "        #to research for lanes using the histogram\n",
    "        dist_betweenLanes_car = (right_fitx[-1] - left_fitx[-1]) * xm_per_pix\n",
    "        dist_betweenLanes_horizont = (right_fitx[0] - left_fitx[0]) * xm_per_pix\n",
    "        self.carPx =  int(left_fitx[-1] +  (right_fitx[-1] - left_fitx[-1])/2.0)\n",
    "        self.carPos = (int(1280/2) - self.carPx)   * xm_per_pix;\n",
    "        if(abs(dist_betweenLanes_car - dist_betweenLanes_horizont) > 2.0):\n",
    "            print (\"Sanity check failed distance of cams {0:.1f} {1:.1f}\".format(dist_betweenLanes_car, dist_betweenLanes_horizont))\n",
    "            self.leftCurverad = None\n",
    "            self.rightCurverad = None\n",
    "            self.leftFit = None\n",
    "            self.rightFit = None\n",
    "            self.noRecoveries +=1\n",
    "        else:\n",
    "            # Fit new polynomials to x,y in world space\n",
    "            left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "            right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "            # Calculate the new radii of curvature\n",
    "            self.leftCurverad  = ((1 + (2*left_fit_cr[0 ]*y_eval*ym_per_pix + left_fit_cr[1 ])**2)**1.5) / np.absolute(2*left_fit_cr[0 ])\n",
    "            self.rightCurverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        return out_img\n",
    "        \n",
    "        \n",
    "    def doAll(self, image, printExample=False):\n",
    "        img = finder.undistortImage(image)\n",
    "        img = finder.findEdges(img)\n",
    "        img = finder.transformPerspective(img)\n",
    "        img = finder.findPolynomials(img)\n",
    "        img = finder.transformPerspective(img, False)\n",
    "        \n",
    "        #add some textual content to the picture\n",
    "        cv2.line(img, ((640),600), ((640),719), (0,0,0), 3)\n",
    "        if not (self.leftCurverad is None):\n",
    "            cv2.line( img, (self.carPx, 600), (self.carPx, 719), (0,0,255), 3)\n",
    "            cv2.putText(img, \"curvMean {0:.2f}m \".format( (self.leftCurverad+ self.rightCurverad)/2.), (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "            cv2.putText(img, \"Car is {0:.2f}m from middle of lane\".format(self.carPos), (10,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "            cv2.putText(img, \"No recoveries {0:d}\".format(self.noRecoveries), (10,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "        else:\n",
    "            cv2.putText(img, \"Sanity check failed - restart histogram search\", (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "            \n",
    "        img = cv2.addWeighted(image, 0.8, img, 0.3, 0)\n",
    "        self.counter += 1\n",
    "        if (self.counter == 20) and (printExample == True):\n",
    "            cv2.imwrite(\"./exampleLane.jpg\", img)\n",
    "        return img\n",
    "    \n",
    "    #/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_\n",
    "    #_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/\n",
    "    #section declaring the static members\n",
    "    #_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/\n",
    "    #/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_            \n",
    "    showImage = staticmethod(showImage)\n",
    "    writeImage = staticmethod(writeImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calibrate the camera\n",
    "We're creating a AdvancedLaneFinder object and trigger the camera calibration as a first step.\n",
    "\n",
    "**NOTICE:** the valid calibration images will be shown with detected corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration using 17 Objectpoints\n",
      "Write persistency to  ./camera_cal/persistency.bin\n"
     ]
    }
   ],
   "source": [
    "finder = AdvancedLaneFinder()\n",
    "#we assume that this IPYNB file is in the root directory and there is \n",
    "#a ./camera_cal folder which contains the calibration images\n",
    "finder.calibrateCameraUsingImage(\"camera_cal\")\n",
    "\n",
    "#optional we can save the calibration data in order to avoid calibration\n",
    "#in other iterations again\n",
    "finder.writeMembers(\"./camera_cal/persistency.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the calibration matrix on a real-world image\n",
    "We'll load now one of the images from the example folder and apply the undistortion operation on it.\n",
    "\n",
    "**Please note:** a sequence of images will now be shown. In order to switch from image to image you have to \n",
    "press any button on your keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read persistency to  ./camera_cal/persistency.bin\n"
     ]
    }
   ],
   "source": [
    "#read persistency if available\n",
    "finder = AdvancedLaneFinder()\n",
    "finder.readMembers(\"./camera_cal/persistency.bin\")\n",
    "\n",
    "#apply undistortion on example image\n",
    "finder.exampleShowUndistorted(\"./test_images/straight_lines1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an image to apply different operations on it\n",
    "\n",
    "We readin an image and depending on the order of operations you're doing, \n",
    "you can see the results of each step. Recall this operation if you want \n",
    "to start from the scratch again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_org = cv2.imread(\"./test_images/straight_lines1.jpg\")\n",
    "img_org = finder.undistortImage(img_org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply edge detection on that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = finder.findEdges(img_org)\n",
    "AdvancedLaneFinder.showImage(img, \"EdgeDetection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into BirdView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the corners we're using for perspective transformation\n",
    "corner_img = finder.initializeTransformMatrix(img_org)\n",
    "AdvancedLaneFinder.showImage(corner_img, \"Selected Corners\")\n",
    "#but the transformation will be done with the already edgy-image\n",
    "img = finder.transformPerspective(img)\n",
    "AdvancedLaneFinder.showImage(img, \"BirdView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the polynomial using the sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = finder.findPolynomials(img)\n",
    "AdvancedLaneFinder.showImage(img, \"Polynomials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge polygon with the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back-transformation of perspective\n",
    "img = finder.transformPerspective(img, False)\n",
    "#merge both images\n",
    "img = cv2.addWeighted(img_org, 0.8, img, 0.3, 0)\n",
    "\n",
    "AdvancedLaneFinder.showImage(img, \"MergedOne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now apply everything on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read persistency to  ./camera_cal/persistency.bin\n",
      "[MoviePy] >>>> Building video ./project_video_result.mp4\n",
      "[MoviePy] Writing video ./project_video_result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [03:08<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_result.mp4 \n",
      "\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "#read persistency if available\n",
    "finder = AdvancedLaneFinder()\n",
    "PERSISTENCE = \"./camera_cal/persistency.bin\"\n",
    "if(True == os.path.isfile(PERSISTENCE)):\n",
    "    finder.readMembers(PERSISTENCE)\n",
    "else:\n",
    "    finder.calibrateCameraUsingImage(\"./camera_cal\")\n",
    "    finder.writeMembers(PERSISTENCE)\n",
    "\n",
    "#initialize the transformation matrix\n",
    "finder.initializeTransformMatrix()\n",
    "\n",
    "clip = VideoFileClip(\"./project_video.mp4\")\n",
    "clipo = clip.fl_image(lambda x: cv2.cvtColor(finder.doAll(\\\n",
    "          cv2.cvtColor(x, cv2.COLOR_RGB2BGR) ), cv2.COLOR_BGR2RGB ))\n",
    "%time clipo.write_videofile(\"./project_video_result.mp4\", audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./project_video_result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"./project_video_result.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
